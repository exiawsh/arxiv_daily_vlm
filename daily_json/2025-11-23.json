[
    {
        "title": "Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination",
        "summary": "Understanding text-rich videos requires reading small, transient textual cues that often demand repeated inspection. Yet most video QA models rely on single-pass perception over fixed frames, leading to hallucinations and failures on fine-grained evidence. Inspired by how humans pause, zoom, and re-read critical regions, we introduce Video-R4 (Reinforcing Text-Rich Video Reasoning with Visual Rumination), a video reasoning LMM that performs visual rumination: iteratively selecting frames, zooming into informative regions, re-encoding retrieved pixels, and updating its reasoning state. We construct two datasets with executable rumination trajectories: Video-R4-CoT-17k for supervised practice and Video-R4-RL-30k for reinforcement learning. We propose a multi-stage rumination learning framework that progressively finetunes a 7B LMM to learn atomic and mixing visual operations via SFT and GRPO-based RL. Video-R4-7B achieves state-of-the-art results on M4-ViteVQA and further generalizes to multi-page document QA, slides QA, and generic video QA, demonstrating that iterative rumination is an effective paradigm for pixel-grounded multimodal reasoning.",
        "url": "http://arxiv.org/abs/2511.17490v1",
        "published_date": "2025-11-21T18:47:09+00:00",
        "updated_date": "2025-11-21T18:47:09+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Yolo Yunlong Tang",
            "Daiki Shimada",
            "Hang Hua",
            "Chao Huang",
            "Jing Bi",
            "Rogerio Feris",
            "Chenliang Xu"
        ],
        "tldr": "The paper introduces Video-R4, a video reasoning LMM that uses iterative visual rumination to understand text-rich videos and achieves state-of-the-art results on several QA tasks.",
        "tldr_zh": "该论文介绍了Video-R4，一种视频推理LMM，它使用迭代视觉沉思来理解富文本视频，并在多个问答任务上实现了最先进的结果。",
        "relevance_score": 8,
        "novelty_claim_score": 9,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    },
    {
        "title": "Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models",
        "summary": "Scaling up multimodal models has enabled remarkable advances in visual understanding and reasoning, but practical demands call for smaller, efficient systems. In this work, we conduct a principled analysis of downscaling intelligence in multimodal models, examining how reduced large language model (LLM) capacity affects multimodal capabilities. Our initial findings reveal an interesting trend: LLM downscaling disproportionately affects visual capabilities, rather than abilities inherited from the LLM. We then examine whether this drop mainly reflects the expected decline in visual reasoning or a more fundamental loss of perceptual abilities. Isolating the effect of LLM downscaling on perception, we find performance still drops sharply, often matching or exceeding the impact on reasoning. To address this bottleneck, we introduce visual extraction tuning, which explicitly trains the model to extract instruction-relevant visual details consistently across tasks. With these extracted visual details, we then apply step-by-step reasoning to generate answers. Together, these components form our Extract+Think approach, setting a new standard for efficiency and performance in this space.",
        "url": "http://arxiv.org/abs/2511.17487v1",
        "published_date": "2025-11-21T18:43:01+00:00",
        "updated_date": "2025-11-21T18:43:01+00:00",
        "categories": [
            "cs.CV"
        ],
        "authors": [
            "Mark Endo",
            "Serena Yeung-Levy"
        ],
        "tldr": "This paper analyzes the impact of downscaling LLMs in multimodal models, finding that visual capabilities are disproportionately affected, particularly in perception, and proposes an 'Extract+Think' approach to mitigate this issue.",
        "tldr_zh": "本文分析了在多模态模型中缩减LLM规模的影响，发现视觉能力受到的影响尤为严重，特别是在感知方面，并提出了“提取+思考”的方法来缓解这个问题。",
        "relevance_score": 8,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 8,
        "overall_priority_score": 8
    }
]